# Instalaci√≥n y Configuraci√≥n de KVM y M√°quinas Virtuales

## Tabla de contenido

- [Desarrollo](#desarrollo)
  - [Fase 1. Configuraci√≥n del sistema anfitri√≥n](#fase1-configuraci√≥n-del-sistema-anfitri√≥n)
  - [Fase 2. Verificaci√≥n de requerimientos m√≠nimos](#fase2-verificaci√≥n-de-requerimientos-m√≠nimos)
  - [Fase 3. Instalaci√≥n de paquetes de virtualizaci√≥n](#fase3-instalaci√≥n-de-paquetes-de-virtualizaci√≥n)
  - [Fase 4. Creaci√≥n de una m√°quina virtual](#fase4-creaci√≥n-de-una-m√°quina-virtual)
- [Pruebas y Validaci√≥n](#pruebasvalidaci√≥n)
- [Bibliograf√≠a](#bibliograf√≠a)

## Desarrollo

### Fase 1. Configuraci√≥n del sistema anfitri√≥n

#### Tarea 1. Personalizar la clave del usuario root

Se personaliza la clave del usuario root del PC asignado ejecutando la orden `passwd`.

#### Tarea 2. Completar la encuesta "Datos PC"

Para completar la encuesta "Datos PC" se procede de la siguiente forma:

1. Identificador del PC asignado: **LQ-D25**
2. Direcci√≥n IP del PC: **10.140.92.125**

Se ejecuta la orden:

```bash
root@lq-d25:/# ip -4 addr show
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: enp6s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    inet 10.140.92.125/24 brd 10.140.92.255 scope global dynamic noprefixroute enp6s0
       valid_lft 9880sec preferred_lft 9880sec
3: virbr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
       valid_lft forever preferred_lft forever
```

La orden `ip` es un comando de utilidad de l√≠nea de comandos en sistemas Linux que se utiliza para mostrar o manipular el enrutamiento, los dispositivos de red, las interfaces y los t√∫neles. 

Se utilizan las opciones:
- `-4` para especificar que solo se deben mostrar las direcciones IPv4
- `addr` para especificar que se quiere obtener informaci√≥n de las direcciones de red
- `show` para indicar que se quiere mostrar la informaci√≥n solicitada

En este caso la direcci√≥n IP del PC en la red local es **10.140.92.125**. Adem√°s, el comando muestra:
- La direcci√≥n utilizada para comunicaci√≥n interna dentro de la misma m√°quina (loopback): **127.0.0.1**
- La direcci√≥n IP de una red virtual: **192.168.122.1**, utilizada en este caso por la red virtual para que m√°quinas virtuales puedan comunicarse entre ellas o con el sistema anfitri√≥n

#### Tarea 3. Comprobar el modo de funcionamiento de SELinux

Se ejecuta la siguiente orden para comprobar que el modo de funcionamiento de SELinux se est√° ejecutando en modo "enforcing":

```bash
root@lq-d25:/# sestatus
SELinux status:                 enabled
SELinuxfs mount:                /sys/fs/selinux
SELinux root directory:         /etc/selinux
Loaded policy name:             targeted
Current mode:                   enforcing
Mode from config file:          enforcing
Policy MLS status:              enabled
Policy deny_unknown status:     allowed
Memory protection checking:     actual (secure)
Max kernel policy version:      33
```
 
El comando `sestatus` se utiliza para mostrar el estado actual de SELinux (Security-Enhaced Linux) en un sistema Linux. SELinux es un m√≥dulo de seguridad del kernel que proporciona un control de acceso aleatorio (MAC), mejorando la seguridad del sistema al limitar los permisos de los procesos.

> **Nota**: El modo "enforcing" (enabled) en SELinux significa que el sistema est√° aplicando activamente las pol√≠ticas de seguridad.

#### Tarea 4. Instalar un entorno gr√°fico GNOME m√≠nimo

Para instalar un entorno gr√°fico GNOME m√≠nimo, primero se debe instalar el grupo de paquetes @base-x:

```bash
dnf groupinstall "base-x" -y
```

Donde:
- `dnf`: herramienta de gesti√≥n de paquetes
- `groupinstall`: instala un grupo de paquetes
- `"base-x"`: nombre del grupo de paquetes que contiene el entorno gr√°fico X
- `-y`: responde "s√≠" a todas las preguntas, evitando la interacci√≥n del usuario

A continuaci√≥n, se instalan los paquetes esenciales de GNOME:

```bash
sudo dnf install -y gnome-shell gnome-terminal nautilus
```

Donde:
- `install`: instala los paquetes espec√≠ficos
- `gnome-shell`: La interfaz gr√°fica de GNOME
- `gnome-terminal`: La terminal de GNOME
- `nautilus`: El gestor de archivos de GNOME

Tambi√©n se debe instalar virt-manager, que permitir√° gestionar m√°quinas virtuales:

```bash
sudo dnf install -y virt-manager
```

Donde:
- `virt-manager`: herramienta gr√°fica para administrar m√°quinas virtuales

Para iniciar el sistema en modo gr√°fico por defecto:

```bash
sudo systemctl set-default graphical.target
```

Donde:
- `systemctl`: herramienta de gesti√≥n de servicios
- `set-default`: establece el objetivo de inicio por defecto
- `graphical.target`: objetivo de inicio para el modo gr√°fico

Ahora para poder iniciar la interfaz gr√°fica habr√≠a que reiniciar el PC o ejecutar:

```bash
sudo systemctl start gdm
```

Donde:
- `start`: inicia el servicio especificado
- `gdm`: es el gestor de pantalla de GNOME

Finalmente, se instalan las herramientas adicionales Firefox y gedit:
 
```bash
sudo dnf install -y firefox gedit
```

Donde:
- `firefox`: navegador web
- `gedit`: editor de texto

#### Tarea 5. Configurar el nombre del sistema

En esta secci√≥n se describe como configurar el nombre del sistema utilizando la herramienta hostnamectl. El objetivo es establecer un identificador FQDN (Full Qualified Domain Name) que siga el patr√≥n IdentificadorPC.vpd.com.

Primero se verifica el nombre actual del sistema con el comando:

```bash
root@LQ-D25:~# hostnamectl status
   Static hostname: (unset)                         
Transient hostname: LQ-D25
         Icon name: computer-desktop
           Chassis: desktop üñ•Ô∏è
        Machine ID: ee3433707aa84f56860cd67efede9ce8
           Boot ID: a8c57ab742fc427ab9883280a554ee97
  Operating System: Fedora Linux 39 (Server Edition)
       CPE OS Name: cpe:/o:fedoraproject:fedora:39
    OS Support End: Tue 2024-11-12
OS Support Expired: 2month 3w 4d                    
            Kernel: Linux 6.9.9-100.fc39.x86_64
      Architecture: x86-64
   Hardware Vendor: ASUS
    Hardware Model: PRIME A520M-A II
  Firmware Version: 3002
     Firmware Date: Thu 2023-02-23
      Firmware Age: 1y 11month 2w
```

Este comando muestra informaci√≥n sobre el nombre del host, incluyendo el nombre est√°tico (el que se usa por defecto al arrancar), el nombre transitorio (asignador por la red) y otra informaci√≥n relevante del sistema. 

A continuaci√≥n, se configura el nuevo hostname:

```bash
sudo hostnamectl set-hostname lq-d25.vpd.com
```

Donde:
- `hostnamectl`: herramienta para controlar el nombre del host
- `set-hostname`: establece el nombre del host
- `lq-d25.vpd.com`: nuevo nombre de dominio completamente cualificado (FQDN)

Despu√©s de ejecutar este comando, el sistema tendr√° el nuevo FQDN configurado.

Este cambio de nombre es importante para la correcta identificaci√≥n del sistema en la red y para las pr√°cticas posteriores de la asignatura, donde se utilizar√° este FQDN para acceder a las m√°quinas virtuales.

### Fase 2. Verificaci√≥n de requerimientos m√≠nimos

#### Tarea 6. Verificar la virtualizaci√≥n del procesador

Para verificar que la extensi√≥n de virtualizaci√≥n est√° habilitada en el procesador, se utiliza el siguiente comando:

```bash
root@lq-d25:~# lscpu | grep Virtualization
Virtualization:                       AMD-V
```

Donde:
- `lscpu`: comando que muestra informaci√≥n sobre la arquitectura del Sistema, incluyendo el procesador
- `grep`: comando que busca patrones en un texto
- `Virtualization`: patr√≥n que se busca en la salida del comando lscpu

En el resultado se indica que el procesador del sistema soporta la tecnolog√≠a de virtualizaci√≥n AMD-V, lo que significa que se puede utilizar para crear y ejecutar m√°quinas virtuales. 

Tambi√©n se puede verificar que la extensi√≥n de virtualizaci√≥n est√° habilitada en el procesador con el siguiente comando:

```bash
root@lq-d25:~# grep -E 'svm|vmx' /proc/cpuinfo
flags‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local user_shstk clzero irperf xsaveerptr rdpru wbnoinvd cppc arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm debug_swap
```

Este comando busca las banderas svm (para procesadores AMD) o vmx (para procesadores Intel) en la salida del comando cat /proc/cpuinfo, que muestra informaci√≥n detallada del procesador. 

#### Tarea 7. Recopilar informaci√≥n del sistema

Para responder a las preguntas sobre el sistema, se utilizan los siguientes comandos:

¬øCu√°ntos de chips de procesador posee el sistema?

```bash
root@lq-d25:~# lscpu | grep "Socket(s):"
```

¬øCu√°ntos n√∫cleos posee cada chip?

```bash
root@lq-d25:~# lscpu | grep "Core(s) per socket:"
Core(s) per socket:                   6
```

Resultado: 6 n√∫cleos por socket. 

¬øCu√°ntos hilos de procesamiento se podr√°n ejecutar en el sistema?

```bash
root@lq-d25:~# lscpu | grep "Thread(s) per core:"
Thread(s) per core:                   2
```

Resultado: 2 hilos por n√∫cleo. 

C√°lculo: 1 socket * 6 n√∫cleos/socket * 2 hilos/n√∫cleos = 12 hilos de procesamiento.

¬øQu√© cantidad de memoria RAM dispone el sistema?

Para estudiar la informaci√≥n de la memoria del PC Podemos ejecutar el siguiente comando:

```bash
root@lq-d25:~# free -h
               total        used        free      shared  buff/cache   available
Mem:            62Gi       4,4Gi        56Gi       123Mi       1,4Gi        57Gi
Swap:           39Gi          0B        39Gi
```

Luego, para averiguar la cantidad de memoria RAM de la que dispone el sistema:

```bash
root@lq-d25:~# free -h | grep Mem | awk '{print $2}'
62Gi
```

Donde:
- `free -h`: es un comando que muestra la informaci√≥n de la memoria del PC en un formato legible para humanos
- `grep Mem`: filtra la salida para mostrar solo la l√≠nea que contiene la informaci√≥n de la memoria principal
- `awk '{print $2}'`: extrae el segundo campo de esa l√≠nea, que corresponde con la cantidad total de memoria RAM

Respuesta: 62 GiB

¬øQu√© cantidad de RAM est√° disponible?

```bash
root@lq-d25:~# free -h | grep Mem | awk '{print $7}'
57Gi
```

Donde: 
- `awk '{print $7}'`: extrae el s√©ptimo campo de la l√≠nea, que corresponde con la cantidad de memoria RAM disponible

Respuesta: 57 GiB

¬øCu√°l es el tama√±o del √°rea de swap?

```bash
root@lq-d25:~# free -h | grep Swap | awk '{print $2}'
39Gi
```

Donde: 
- `grep Swap`: muestra solo la l√≠nea que contiene informaci√≥n del √°rea de swap

Resultado: 39 GiB

¬øCu√°l es el estado de ocupaci√≥n y espacio libre del almacenamiento persistente?

```bash
root@lq-d25:~# df -h
S.ficheros     Tama√±o Usados  Disp Uso% Montado en
/dev/sda7        144G   4,7G  132G   4% /
devtmpfs         4,0M      0  4,0M   0% /dev
tmpfs             32G      0   32G   0% /dev/shm
tmpfs             13G   9,8M   13G   1% /run
tmpfs             32G    20K   32G   1% /tmp
tmpfs            6,3G   3,7M  6,3G   1% /run/user/0
```

El comando df -h proporciona informaci√≥n detallada sobre el estado de ocupaci√≥n y espacio libre del almacenamiento persistente en el sistema. A continuaci√≥n, se analiza la salida del comando:

- `/dev/sda7`: es la partici√≥n principal del disco duro, donde est√° instalado el sistema operativo y las aplicaciones. Tiene un tama√±o total de 144 GB, de los cuales se est√°n utilizando 4.7 GB, lo que representa un 4% de uso.
- `devtmpfs`: es un sistema de archivos temporal en memoria (tmpfs) utilizado para dispositivos
- `tmpfs`: son otros sistemas de archivos temporales en memoria utilizados para diferentes prop√≥sitos:
  - `/dev/shm`: memoria compartida entre procesos
  - `/run`: archivos de estado del sistema y de los servivios
  - `/tmp`: archivos temporales
  - `/run/user/0`: archivos temporales del usuario root

En general, el sistema tiene suficiente espacio libre en el almacenamiento persistente.

### Fase 3. Instalaci√≥n de paquetes de virtualizaci√≥n

#### Tarea 8. Instalar el entorno de virtualizaci√≥n KVM

Para instalar el entorno de virtualizaci√≥n KVM, se deben ejecutar los siguientes comandos:

```bash
root@lq-d25:~# dnf groupinstall "Virtualization " --with-optional -y
√öltima comprobaci√≥n de caducidad de metadatos hecha hace 0:51:35, el vie 07 feb 2025 19:33:38.
Dependencias resueltas.
============================================================================================================================
Paquete                      Arquitectura                Versi√≥n                        Repositorio                   Tam.
============================================================================================================================
Instalando grupos:
Headless Virtualization                                                                                                   
 
Resumen de la transacci√≥n
============================================================================================================================
 
¬°Listo!
```

Este comando instala el grupo de paquetes "Virtualization", incluyendo los paquetes opcionales, utilizando el gestor de paquetes dnf. La opci√≥n --with-optional asegura que se instalen todos los paquetes necesarios para un entorno de virtualizaci√≥n completo. 

Luego:

```bash
root@lq-d25:~# dnf groupinstall "Virtualization-headless" --with-optional -y
√öltima comprobaci√≥n de caducidad de metadatos hecha hace 0:56:23, el vie 07 feb 2025 19:33:38.
Dependencias resueltas.
============================================================================================================================
Paquete                      Arquitectura                Versi√≥n                        Repositorio                   Tam.
============================================================================================================================
Instalando grupos:
Headless Virtualization                                                                                                   
 
Resumen de la transacci√≥n
============================================================================================================================
 
¬°Listo!
```

Este comando instala el grupo de paquetes "Virtualization-headless", que proporciona las herramientas de virtualizaci√≥n para sistemas sin interfaz gr√°fica. Al igual que en el comando anterior, la opci√≥n --with-optional se utiliza para instalar los paquetes opcionales. 

Una vez instalado el entorno de virtualizaci√≥n, se puede verificar la instalaci√≥n ejecutando el comando:

```bash
root@lq-d25:~# virsh cpu-models x86_64
486
pentium
pentium2
pentium3
pentiumpro
coreduo
n270
core2duo
qemu32
kvm32
cpu64-rhel5
cpu64-rhel6
qemu64
kvm64
 ‚Ä¶
```

Este comando lista los modelos de CPU soportados por la arquitectura x86_64. La salida del comando mostrar√° una lista de los modelos de CPU disponibles para las m√°quinas virtuales. 

#### Tarea 9. Configurar y verificar el servicio virtnetworkd

Antes de configurar el servicio virtnetworkd se debe iniciar el servicio libvirtd, que es el demonio de virtualizaci√≥n principal, para ello se utiliza el siguiente comando:

```bash
root@lq-d25:~# sudo systemctl enable --now libvirtd
Created symlink /etc/systemd/system/multi-user.target.wants/libvirtd.service ‚Üí /usr/lib/systemd/system/libvirtd.service.
Created symlink /etc/systemd/system/sockets.target.wants/libvirtd.socket ‚Üí /usr/lib/systemd/system/libvirtd.socket.
Created symlink /etc/systemd/system/sockets.target.wants/libvirtd-ro.socket ‚Üí /usr/lib/systemd/system/libvirtd-ro.socket.
```

Este comando habilita el servicio libvirtd para que se inicie autom√°ticamente en el arranque del sistema y lo inicia inmediatamente. La salida del comando muestra la creaci√≥n de enlaces simb√≥licos, lo que indica que el servicio se ha habilitado correctamente. 

Para verificar que el servicio libvirtd se est√° ejecutando correctamente se utiliza el siguiente comando:

```bash
root@lq-d25:~# systemctl status libvirtd
‚óè libvirtd.service - Virtualization daemon
     Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled; preset: disabled)
    Drop-In: /usr/lib/systemd/system/service.d
             ‚îî‚îÄ10-timeout-abort.conf
     Active: active (running) since Fri 2025-02-07 20:28:27 WET; 11s ago
TriggeredBy: ‚óè libvirtd-ro.socket
             ‚óè libvirtd.socket
             ‚óã libvirtd-tls.socket
             ‚óè libvirtd-admin.socket
             ‚óã libvirtd-tcp.socket
       Docs: man:libvirtd(8)
https://libvirt.org
   Main PID: 10869 (libvirtd)
      Tasks: 22 (limit: 32768)
     Memory: 18.0M
        CPU: 374ms
     CGroup: /system.slice/libvirtd.service
             ‚îú‚îÄ10869 /usr/sbin/libvirtd --timeout 120
             ‚îú‚îÄ10970 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/>
             ‚îî‚îÄ10971 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/>
 
feb 07 20:28:27 lq-d25.vpc.com systemd[1]: Started libvirtd.service - Virtualization daemon.
feb 07 20:28:27 lq-d25.vpc.com dnsmasq[10970]: started, version 2.90 cachesize 150
feb 07 20:28:27 lq-d25.vpc.com dnsmasq[10970]: compile time options: IPv6 GNU-getopt DBus no-UBus i18n IDN2 DHCP DHCPv6 no->
feb 07 20:28:27 lq-d25.vpc.com dnsmasq-dhcp[10970]: DHCP, IP range 192.168.122.2 -- 192.168.122.254, lease time 1h
feb 07 20:28:27 lq-d25.vpc.com dnsmasq-dhcp[10970]: DHCP, sockets bound exclusively to interface virbr0
feb 07 20:28:27 lq-d25.vpc.com dnsmasq[10970]: reading /etc/resolv.conf
feb 07 20:28:27 lq-d25.vpc.com dnsmasq[10970]: using nameserver 127.0.0.53#53
feb 07 20:28:27 lq-d25.vpc.com dnsmasq[10970]: read /etc/hosts - 8 names
feb 07 20:28:27 lq-d25.vpc.com dnsmasq[10970]: read /var/lib/libvirt/dnsmasq/default.addnhosts - 0 names
feb 07 20:28:27 lq-d25.vpc.com dnsmasq-dhcp[10970]: read /var/lib/libvirt/dnsmasq/default.hostsfile
```

A continuaci√≥n, para verificar que el servicio libvirtd est√° funcionando correctamente y que no hay m√°quinas virtuales en ejecuci√≥n, se utiliza el siguiente comando:

```bash
root@lq-d25:~# sudo virsh list --all
Id   Nombre   Estado
-----------------------
```

La salida del comando muestra una l√≠nea vac√≠a, ya que no se ha creado ninguna m√°quina virtual todav√≠a. 

Para configurar el sistema anfitri√≥n para que el servicio virtnetworkd se inicie durante el arranque, se utiliza la siguiente orden:

```bash
root@lq-d25:~# systemctl enable --now virtnetworkd
Created symlink /etc/systemd/system/multi-user.target.wants/virtnetworkd.service ‚Üí /usr/lib/systemd/system/virtnetworkd.service.
```

Donde:
- `systemctl`: herramienta para controlar los servicios del sistema
- `enable`: habilita el servicio para que se inicie autom√°ticamente en el arranque del sistema
- `--now`: flag para iniciar el servicio inmediatamente
- `virtnetworkd`: nombre del servicio que gestiona las redes virtuales

Una vez ejecutado el comando, el servicio virtnetworkd estar√° habilitado e iniciado. 

Para verificar que el servicio se est√° ejecutando correctamente, se puede utilizar el siguiente comando:

```bash
root@lq-d25:~# systemctl status virtnetworkd
‚óè virtnetworkd.service - Virtualization network daemon
     Loaded: loaded (/usr/lib/systemd/system/virtnetworkd.service; enabled; preset: disabled)
    Drop-In: /usr/lib/systemd/system/service.d
             ‚îî‚îÄ10-timeout-abort.conf
     Active: active (running) since Fri 2025-02-07 20:36:27 WET; 10s ago
TriggeredBy: ‚óè virtnetworkd-admin.socket
             ‚óè virtnetworkd.socket
             ‚óè virtnetworkd-ro.socket
       Docs: man:virtnetworkd(8)
https://libvirt.org
   Main PID: 11524 (virtnetworkd)
      Tasks: 19 (limit: 76221)
     Memory: 3.9M
        CPU: 157ms
     CGroup: /system.slice/virtnetworkd.service
             ‚îî‚îÄ11524 /usr/sbin/virtnetworkd --timeout 120
 
feb 07 20:36:27 lq-d25.vpc.com systemd[1]: Starting virtnetworkd.service - Virtualization network daemon...
feb 07 20:36:27 lq-d25.vpc.com systemd[1]: Started virtnetworkd.service - Virtualization network daemon.
```

La salida del comando indica que el servicio est√° activo y en ejecuci√≥n. 

Ahora, para verificar que los m√≥dulos del kernel kvm est√°n cargados, utilizamos el siguiente comando:

```bash
root@lq-d25:~# lsmod | grep kvm
kvm_amd               217088  0
kvm                  1441792  1 kvm_amd
ccp                   180224  1 kvm_amd
```

Este comando lista los m√≥dulos del kernel cargados y filtra la salida para mostrar solo las l√≠neas que contienen "kvm". 

La salida del comando muestra el m√≥dulo kvm_amd (el sistema tiene procesador AMD), lo que indica que el hipervisor KVM est√° funcionando correctamente. 

Finalmente, para comprobar que la configuraci√≥n de SELinux permite que el entorno de virtualizaci√≥n utilice el servicio NFS, se ejecuta el siguiente comando:

```bash
root@lq-d25:~# getsebool virt_use_nfs
virt_use_nfs --> on
```

La salida del comando indica que los procesos del entorno de virtualizaci√≥n pueden utilizar el servicio NFS.

### Fase 4. Creaci√≥n de una m√°quina virtual

#### Tarea 10. Crear una m√°quina virtual

Para crear una m√°quina virtual, primero se debe montar el directorio que contiene la imagen ISO de Fedora Server 41 a trav√©s de NFS:

```bash
root@lq-d25:~# sudo mount -t nfs 10.22.146.216:/imagenes/fedora/41/isos/x86_64 /mnt
Created symlink /run/systemd/system/remote-fs.target.wants/rpc-statd.service ‚Üí /usr/lib/systemd/system/rpc-statd.service.
```

Este comando monta el directorio /imagenes/fedora/41/isos/x86_64 del servidor 10.22.146.216 en el directorio local /mnt.

Luego, se copia la imagen ISO a un directorio local, por ejemplo:

```bash
root@lq-d25:/mnt# sudo mkdir -p /ISO
root@lq-d25:/mnt# sudo cp /mnt/Fedora-Server-netinst-x86_64-41-1.4.iso /ISO/
```

Despu√©s de copiar la imagen, se desmonta el directorio /mnt:

```bash
root@lq-d25:/# sudo umount /mnt
```

A continuaci√≥n, se utiliza la herramienta gr√°fica virt-manager para crear la m√°quina virtual. Se deben proporcionar los siguientes par√°metros:
1. Nombre de la m√°quina virtual: mvp1
2. Medio de instalaci√≥n: Imagen ISO local 
 
Ilustraci√≥n 1. Herramienta virt-manager. Configuraci√≥n del medio de instalaci√≥n del sistema operativo
3. Cantidad de memoria: 2GB
4. N√∫mero de procesadores: 1
5. Disco de la m√°quina virtual: 10GB
6. Interfaz de red: 1 interfaz en modo NAT

Una vez creada la m√°quina virtual, se inicia la instalaci√≥n del sistema operativo Fedora Server 41.  Se debe realizar una instalaci√≥n m√≠nima y habilitar la cuenta de administraci√≥n root con acceso SSH. 
 
Ilustraci√≥n 2. Herramienta virt-manager. Configuraci√≥n del usuario root

Una vez terminada la instalaci√≥n, se comprueba la conexi√≥n SSH a nuestra m√°quina virtual:

```bash
root@lq-d25:/# ssh root@192.168.122.123
The authenticity of host '192.168.122.123 (192.168.122.123)' can't be established.
ED25519 key fingerprint is SHA256:gRFGvZlUIel5P1EJEdiEEgvXQ48k7iMy9Oz5SDPY2h4.
This key is not known by any other names.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '192.168.122.123' (ED25519) to the list of known hosts.
root@192.168.122.123's password: 
Web console: https://localhost:9090/ or https://192.168.122.123:9090/

Last login: Fri Feb 14 19:37:07 2025
root@localhost:~# ls
anaconda-ks.cfg
```

Una vez finalizada la instalaci√≥n del sistema operativo en la m√°quina virtual, se deben realizar los siguientes pasos de configuraci√≥n:

Instalar el servicio qemu-gest-agent

El servicio qemu-guest-agent se utiliza para mejorar la integraci√≥n entre la m√°quina virtual y el sistema anfitri√≥n. Permite realizar tareas como sincronizar la hora, obtener informaci√≥n del sistema y ejecutar comandos en la m√°quina virtual desde el anfitri√≥n. Para instalar este servicio se ejecuta la siguiente orden:

```bash
root@localhost:~# sudo dnf install -y qemu-guest-agent
Actualizando y cargando repositorios:
Repositorios cargados.
Package                  Arch    Version                  Repository        Size
Installing:
qemu-guest-agent        x86_64  2:9.1.2-3.fc41           updates      962.9 KiB



Transaction Summary:
Installing:         1 package



El tama√±o total de paquetes entrantes es 313 KiB. Se necesita descargar 313 KiB.
Despu√©s de esta operaci√≥n, 963 KiB extra ser√°n utilizados (instalar 963 KiB, eliminar 0 B).
[1/1] qemu-guest-agent-2:9.1.2-3.fc41.x 100% | 569.4 KiB/s | 313.2 KiB |  00m01s
--------------------------------------------------------------------------------
[1/1] Total                             100% | 375.9 KiB/s | 313.2 KiB |  00m01s
Ejecutando transacci√≥n
[1/3] Verificar archivos de paquete     100% | 333.0   B/s |   1.0   B |  00m00s
[2/3] Preparar transacci√≥n             100% |  18.0   B/s |   1.0   B |  00m00s
[3/3] Instalando qemu-guest-agent-2:9.1 100% |   1.2 MiB/s | 965.6 KiB |  00m01s
>>> Ejecutando post-install scriptlet: qemu-guest-agent-2:9.1.2-3.fc41.x86_64
>>> Finalizado post-install scriptlet: qemu-guest-agent-2:9.1.2-3.fc41.x86_64
>>> Salida del scriptlet:
>>> Created symlink '/etc/systemd/system/dev-virtio\x2dports-org.qemu.guest_agen
>>> Unit /usr/lib/systemd/system/qemu-guest-agent.service is added as a dependen
>>> 
¬°Completado!
```

Este comando instala el paquete qemu-guest-agent utilizando el gestor de paquetes dnf. 

Habilitar e iniciar el servicio qemu-guest-agent

Una vez instalado el paquete, se debe habilitar e inicializar el servicio qemu-guest-agent para que se ejecute en el arranque del sistema. Para ello, se utiliza el siguiente comando:

```bash
root@localhost:~# sudo systemctl enable --now qemu-guest-agent
Unit /usr/lib/systemd/system/qemu-guest-agent.service is added as a dependency to a non-existent unit dev-virtio\x2dports-org.qemu.guest_agent.0.device.

Este comando habilita e inicia el servicio qemu-guest-agent. La salida del comando indica que el servicio se ha a√±adido como dependencia a una unidad no existente, esto se debe a que el servicio qemu-guest-agent depende de la disponibilidad de dispositivos virtio, que se crean din√°micamente cuando la m√°quina virtual se inicia. 

Establecer el nombre del Sistema

Para establecer el nombre del sistema en la m√°quina virtual como mvp1.vpd.com, se utiliza el siguiente comando:

```bash
root@localhost:~# sudo hostnamectl set-hostname mvp1.vpd.com

Este comando establece el nombre de host est√°tico de la m√°quina virtual como mvp1.vpd.com.

Para verificar que el nombre del sistema se ha establecido correctamente:

```bash
root@localhost:~# hostnamectl
     Static hostname: mvp1.vpd.com
           Icon name: computer-vm
             Chassis: vm üñ¥
          Machine ID: 6d2630bf3d2046a589c37eaa7313994b
             Boot ID: 4ee2bc753f724da7a1b60f1c189b497f
        Product UUID: 77722a52-4d29-4f91-a688-453a1fbfad52
      Virtualization: kvm
    Operating System: Fedora Linux 41 (Server Edition)    
         CPE OS Name: cpe:/o:fedoraproject:fedora:41
      OS Support End: Mon 2025-12-15
OS Support Remaining: 9month 4w 1d
              Kernel: Linux 6.12.11-200.fc41.x86_64
        Architecture: x86-64
     Hardware Vendor: QEMU
      Hardware Model: Standard PC _Q35 + ICH9, 2009_
    Firmware Version: 1.16.3-1.fc39
       Firmware Date: Tue 2014-04-01
        Firmware Age: 10y 10month 2w 1d      
```

Configurar el acceso SSH con clave p√∫blico/privada

Para permitir el acceso SSH desde el sistema anfitri√≥n a la m√°quina virtual utilizando autenticaci√≥n con clave p√∫blica/privada, se siguen estos pasos:

Generar un par de claves SSH en el sistema anfitri√≥n:

```bash
root@lq-d25:/# ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa
Generating public/private rsa key pair.
/root/.ssh/id_rsa already exists.
Overwrite (y/n)? y
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /root/.ssh/id_rsa
Your public key has been saved in /root/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:4zKf+4PBMp2TVNCOTBiZNHFCKfjLvniX91nfaJ7yvLs root@lq-d25.vpc.com
The key's randomart image is:
+---[RSA 4096]----+
|   . oBBoo       |
|  . . =+. o      |
|   . . o +       |
|    .   + .      |
|   . . +So       |
|    o o.B.       |
|   .  o+.+  .    |
|   .o o+o..o.o.+ |
|  ...o .+++. =E+.|
+----[SHA256]-----+
```

El comando ssh-keygen genera un par de claves SSH. 

A continuaci√≥n, se copia la clave p√∫blica al sistema de la m√°quina virtual:

```bash
root@lq-d25:/# ssh-copy-id root@192.168.122.123
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@192.168.122.123's password: 

Number of key(s) added: 1

Now try logging into the machine, with:   "ssh 'root@192.168.122.123'"
and check to make sure that only the key(s) you wanted were added. 
```

El comando ssh-copy-id copia la clave p√∫blica al archivo authorized_keys del usuario root en la m√°quina virtual. 

Con eso, se completa la configuraci√≥n del acceso SSH con la clave p√∫blica/privada. Ahora se puede iniciar sesi√≥n en la m√°quina virtual desde el sistema anfitri√≥n utilizando el siguiente comando sin necesidad de introducir la contrase√±a:

```bash
root@lq-d25:/# ssh root@192.168.122.123
Web console: https://localhost:9090/ or https://192.168.122.123:9090/
```

Configurar el Sistema anfitri√≥n para poder realizar conexiones TCP/IP a la m√°quina virtual utilizando el identificador FQDN de esta

Para acceder a la m√°quina virtual mediante SSH utilizando su nombre de dominio mvp1.vpd.com, primero se debe obtener la direcci√≥n IP de la m√°quina virtual:

```bash
root@mvp1:~# ip a | grep 'inet' | grep -v '127.0.0.1'
    inet6 ::1/128 scope host noprefixroute 
    inet 192.168.122.123/24 brd 192.168.122.255 scope global dynamic noprefixroute enp1s0
    inet6 fe80::5054:ff:fe33:86f/64 scope link noprefixroute
```

A continuaci√≥n, se debe editar el archivo /etc/hosts en el sistema anfitri√≥n y a√±adir una l√≠nea que asocie la direcci√≥n IP de la m√°quina virtual con su nombre de dominio. Para ello se utiliza un editor de texto como nano:

```bash
root@lq-d25:/# sudo nano etc/hosts 
```

Se a√±ade la siguiente l√≠nea al final del archivo:

```bash
192.168.122.123‚ÄÉ‚ÄÉmvp1.vpd.com   
```

Donde 192.168.122.123 es la direcci√≥n IP de la m√°quina virtual obtenida anteriormente. 

Despu√©s de guardar los cambios en el archivo se puede comprobar la conexi√≥n con la m√°quina virtual utilizando el comando ping:

```bash
root@lq-d25:/# ping -c 4 mvp1.vpd.com
PING mvp1.vpd.com (192.168.122.123) 56(84) bytes of data.
64 bytes from mvp1.vpd.com (192.168.122.123): icmp_seq=1 ttl=64 time=0.309 ms
64 bytes from mvp1.vpd.com (192.168.122.123): icmp_seq=2 ttl=64 time=0.399 ms
64 bytes from mvp1.vpd.com (192.168.122.123): icmp_seq=3 ttl=64 time=0.227 ms
64 bytes from mvp1.vpd.com (192.168.122.123): icmp_seq=4 ttl=64 time=0.394 ms

--- mvp1.vpd.com ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3059ms
rtt min/avg/max/mdev = 0.227/0.332/0.399/0.070 ms
```

Finalmente, se puede iniciar sesi√≥n en la m√°quina virtual mediante SSH utilizando su nombre de dominio:

```bash
root@lq-d25:/# ssh root@mvp1.vpd.com
The authenticity of host 'mvp1.vpd.com (192.168.122.123)' can't be established.
ED25519 key fingerprint is SHA256:gRFGvZlUIel5P1EJEdiEEgvXQ48k7iMy9Oz5SDPY2h4.
This host key is known by the following other names/addresses:
    ~/.ssh/known_hosts:1: 192.168.122.123
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added 'mvp1.vpd.com' (ED25519) to the list of known hosts.
Web console: https://localhost:9090/ or https://192.168.122.123:9090/

Last login: Fri Feb 14 19:54:07 2025 from 192.168.122.1
```

Se inicia sesi√≥n correctamente en la m√°quina virtual sin necesidad de introducir la direcci√≥n IP.

## Pruebas y Validaci√≥n

Una vez finalizadas las tareas, se procede a la verificaci√≥n de la instalaci√≥n y configuraci√≥n del sistema anfitri√≥n y la m√°quina virtual:

Verificar el modo de ejecuci√≥n de SELinux

Se utiliza el comando getenforce para verificar que SELinux se est√° ejecutando en modo "enforcing".

```bash
root@lq-d25:/# getenforce
Enforcing
```

Verificar el estado del servicio virtnetworkd

Se utiliza el comando:

```bash
root@lq-d25:/# systemctl status virtnetworkd
‚óè virtnetworkd.service - Virtualization network daemon
     Loaded: loaded (/usr/lib/systemd/system/virtnetworkd.service; enabled; pre>
    Drop-In: /usr/lib/systemd/system/service.d
             ‚îî‚îÄ10-timeout-abort.conf
     Active: active (running) since Fri 2025-02-14 19:18:01 WET; 1h 9min ago
TriggeredBy: ‚óè virtnetworkd-ro.socket
             ‚óè virtnetworkd-admin.socket
             ‚óè virtnetworkd.socket
       Docs: man:virtnetworkd(8)
             https://libvirt.org
   Main PID: 5729 (virtnetworkd)
      Tasks: 21 (limit: 76221)
     Memory: 12.2M
        CPU: 648ms
     CGroup: /system.slice/virtnetworkd.service
             ‚îú‚îÄ1251 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/defa>
             ‚îú‚îÄ1252 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/defa>
             ‚îî‚îÄ5729 /usr/sbin/virtnetworkd --timeout 120
```

La orden comprueba que el servicio virtnetworkd se est√° ejecutando y est√° configurado para iniciarse en el arranque del sistema.

Se comprueba que el estado del servicio est√° active (running) y est√° habilitado para el arranque.

Verificar la carga de los m√≥dulos del kernel kvm y kvm_amd

```bash
root@lq-d25:/# lsmod | grep kvm
kvm_amd               217088  3
kvm                  1441792  2 kvm_amd
ccp                   180224  1 kvm_amd
```

Verificar la configuraci√≥n de la m√°quina virtual mvp1

Se utiliza el siguiente comando:

```bash
root@lq-d25:/# virsh dominfo mvp1
Id:             -
Nombre:         mvp1
UUID:           77722a52-4d29-4f91-a688-453a1fbfad52
Tipo de sistema operatuvo: hvm
Estado:         apagado
CPU(s):         1
Memoria m√°xima: 2097152 KiB
Memoria utilizada: 2097152 KiB
Persistente:    si
Autoinicio:     desactivar
Guardar administrado: no
Modelo de seguridad: selinux
DOI de seguridad: 0
```

La salida del comando debe muestra la informaci√≥n de configuraci√≥n de la m√°quina virtual, incluyendo el nombre (mvp1), la cantidad de memoria RAM, el n√∫mero de CPUs, etc.

Verificar la interfaz de red de la m√°quina virtual mvp1

Se utiliza el comando:

```bash
root@lq-d25:/# virsh domiflist mvp1
Interfaz   Tipo      Fuente    Modelo   MAC
------------------------------------------------------------
-          network   default   virtio   52:54:00:33:08:6f
```

La salida del comando muestra la informaci√≥n de la interfaz de red, incluyendo el tipo, la fuente y la direcci√≥n MAC.

Verificar la conectividad de la m√°quina virtual mvp1

Se utiliza el comando ping para verificar la conectividad de la m√°quina virtual mvp1 con el host anfitri√≥n y con el exterior.

Conectividad con el host anfitri√≥n: Se ejecuta el siguiente comando desde el sistema anfitri√≥n.

```bash
root@lq-d25:/# ping -c 4 mvp1.vpd.com
PING mvp1.vpd.com (192.168.122.123) 56(84) bytes of data.
64 bytes from mvp1.vpd.com (192.168.122.123): icmp_seq=1 ttl=64 time=0.252 ms
64 bytes from mvp1.vpd.com (192.168.122.123): icmp_seq=2 ttl=64 time=0.385 ms
64 bytes from mvp1.vpd.com (192.168.122.123): icmp_seq=3 ttl=64 time=0.367 ms
^C
--- mvp1.vpd.com ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2051ms
rtt min/avg/max/mdev = 0.252/0.334/0.385/0.058 ms
```

Conectividad con el exterior: Se ejecuta el siguiente comando desde la m√°quina virtual.

```bash
root@mvp1:~# ping -4 8.8.8.8
PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=114 time=30.0 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=114 time=30.3 ms

^C--- 8.8.8.8 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1002ms
rtt min/avg/max/mdev = 30.038/30.147/30.257/0.109 ms
```

Verificar la instalaci√≥n y el estado del agente qemu-guest-agent

```bash
root@mvp1:~# systemctl status qemu-guest-agent
‚óè qemu-guest-agent.service - QEMU Guest Agent
     Loaded: loaded (/usr/lib/systemd/system/qemu-guest-agent.service; enabled;>
    Drop-In: /usr/lib/systemd/system/service.d
             ‚îî‚îÄ10-timeout-abort.conf, 50-keep-warm.conf
     Active: active (running) since Fri 2025-02-14 20:36:53 WET; 2min 51s ago
Invocation: 55601c5735c74c248c7a6524e9b1e551
   Main PID: 857 (qemu-ga)
      Tasks: 2 (limit: 2307)
     Memory: 2.3M (peak: 2.6M)
        CPU: 5ms
     CGroup: /system.slice/qemu-guest-agent.service
             ‚îî‚îÄ857 /usr/bin/qemu-ga --method=virtio-serial --path=/dev/virtio-p>
```

El estado del servicio debe es active (running) y est√° habilitado para el arranque.

Verificar el acceso SSH a la m√°quina virtual

```bash
root@lq-d25:/# ssh root@mvp1.vpd.com
Web console: https://mvp1.vpd.com:9090/ or https://192.168.122.123:9090/

Last login: Fri Feb 14 20:38:37 2025 from 192.168.122.1
```

Se ha iniciado sesi√≥n en la m√°quina virtual sin necesidad de introducir la contrase√±a, lo que indica que el acceso SSH con clave p√∫blica/privada est√° configurado correctamente.

## Soluci√≥n de Problemas Comunes

Durante la configuraci√≥n de un entorno de virtualizaci√≥n KVM pueden surgir diferentes problemas. A continuaci√≥n, se presentan algunas situaciones comunes y sus posibles soluciones:

### Problemas con la virtualizaci√≥n del procesador

**Problema**: El sistema indica que no soporta la virtualizaci√≥n por hardware.

**Soluci√≥n**: 
1. Verificar que el procesador soporta virtualizaci√≥n con el comando `lscpu | grep Virtualization`
2. Si el procesador soporta virtualizaci√≥n pero no aparece habilitada, es posible que est√© desactivada en la BIOS/UEFI. Entrar en la configuraci√≥n de la BIOS/UEFI durante el arranque y activar las opciones de virtualizaci√≥n (VT-x para Intel o AMD-V para AMD).

### Problemas con SELinux

**Problema**: La m√°quina virtual no puede acceder a recursos compartidos.

**Soluci√≥n**:
1. Verificar el estado de `virt_use_nfs` con `getsebool virt_use_nfs`
2. Si est√° desactivado, activarlo con `setsebool -P virt_use_nfs on`
3. Para compartir sistemas de archivos locales: `setsebool -P virt_use_samba on`

### Problemas de red

**Problema**: La m√°quina virtual no tiene conexi√≥n a Internet o al sistema anfitri√≥n.

**Soluci√≥n**:
1. Verificar que el servicio `virtnetworkd` est√° activo: `systemctl status virtnetworkd`
2. Comprobar la configuraci√≥n de red en la m√°quina virtual con `virsh domiflist nombre_vm`
3. Verificar la configuraci√≥n de IP con `ip addr show` dentro de la m√°quina virtual
4. Asegurarse de que el firewall no est√° bloqueando las conexiones: `firewall-cmd --list-all`
5. Si es necesario, permitir el tr√°fico de virtualizaci√≥n: `firewall-cmd --permanent --add-rich-rule='rule service name=libvirt accept'`

### Problemas con qemu-guest-agent

**Problema**: Error al iniciar qemu-guest-agent en la m√°quina virtual.

**Soluci√≥n**:
1. Verificar que el paquete est√° correctamente instalado: `rpm -q qemu-guest-agent`
2. Comprobar que el canal virtio est√° habilitado en la configuraci√≥n de la m√°quina virtual
3. Reiniciar el servicio: `systemctl restart qemu-guest-agent`
4. Si persiste el error, verificar los logs: `journalctl -u qemu-guest-agent`

### Problemas de rendimiento

**Problema**: La m√°quina virtual tiene un rendimiento lento.

**Soluci√≥n**:
1. Verificar la asignaci√≥n de recursos (CPU, memoria) con `virsh dominfo nombre_vm`
2. Ajustar la configuraci√≥n seg√∫n sea necesario con `virsh edit nombre_vm`
3. Comprobar que no hay procesos consumiendo excesivos recursos en el anfitri√≥n con `top` o `htop`
4. Considerar el uso de dispositivos virtio para mejor rendimiento (especialmente para discos e interfaces de red)

## Conclusiones

En esta pr√°ctica se ha completado con √©xito la instalaci√≥n y configuraci√≥n de un entorno de virtualizaci√≥n KVM en Fedora Linux. A continuaci√≥n, se resumen los principales logros y conocimientos adquiridos:

1. **Configuraci√≥n del sistema anfitri√≥n**: Se configur√≥ adecuadamente el sistema operativo base, asegurando que SELinux estuviera en modo enforcing para mantener la seguridad del sistema.

2. **Verificaci√≥n de requisitos**: Se comprob√≥ que el hardware del sistema cumpl√≠a con los requisitos necesarios para la virtualizaci√≥n, destacando la presencia de extensiones de virtualizaci√≥n en el procesador (AMD-V).

3. **Instalaci√≥n de herramientas de virtualizaci√≥n**: Se instalaron correctamente los paquetes necesarios para KVM, tanto con interfaz gr√°fica como en modo headless.

4. **Creaci√≥n de m√°quina virtual**: Se cre√≥ una m√°quina virtual con Fedora Server 41, configurando correctamente sus par√°metros de red, acceso SSH y nombre de host.

5. **Configuraci√≥n avanzada**: Se implement√≥ la autenticaci√≥n SSH por clave p√∫blica/privada y se configur√≥ el sistema para poder acceder a la m√°quina virtual mediante su FQDN.

El entorno implementado proporciona una base s√≥lida para desplegar distintos servicios virtualizados, aprovechando las capacidades de KVM y las herramientas de gesti√≥n proporcionadas por libvirt.

## Bibliograf√≠a

1. Documentaci√≥n oficial de KVM: [https://www.linux-kvm.org/page/Documents](https://www.linux-kvm.org/page/Documents)

2. Documentaci√≥n de Fedora sobre virtualizaci√≥n: [https://docs.fedoraproject.org/en-US/quick-docs/virtualization-getting-started/](https://docs.fedoraproject.org/en-US/quick-docs/virtualization-getting-started/)

3. Red Hat Documentation - Configuraci√≥n y administraci√≥n de la virtualizaci√≥n: [https://access.redhat.com/documentation/es-es/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/index](https://access.redhat.com/documentation/es-es/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/index)

4. Libvirt Wiki: [https://wiki.libvirt.org/](https://wiki.libvirt.org/)

5. SELinux Project Wiki: [https://selinuxproject.org/page/Main_Page](https://selinuxproject.org/page/Main_Page)
