# Práctica 8: Implementación y Validación de Agregación de Enlaces de Red mediante Bonding en Entornos Virtualizados

## Tabla de Contenidos

- [Práctica 8: Implementación y Validación de Agregación de Enlaces de Red mediante Bonding en Entornos Virtualizados](#práctica-8-implementación-y-validación-de-agregación-de-enlaces-de-red-mediante-bonding-en-entornos-virtualizados)
  - [Tabla de Contenidos](#tabla-de-contenidos)
  - [Introducción](#introducción)
  - [Objetivos](#objetivos)
  - [Fase 1: Preparación del Entorno Virtual](#fase-1-preparación-del-entorno-virtual)
    - [Tarea 1.1: Creación de la Máquina Virtual](#tarea-11-creación-de-la-máquina-virtual)
    - [Tarea 1.2: Configuración Inicial del Sistema](#tarea-12-configuración-inicial-del-sistema)
      - [Actualización del sistema](#actualización-del-sistema)
      - [Instalación y configuración del agente QEMU](#instalación-y-configuración-del-agente-qemu)
      - [Configuración del hostname](#configuración-del-hostname)
      - [Configuración de acceso SSH](#configuración-de-acceso-ssh)
  - [Fase 2: Implementación de Agregación de Enlaces](#fase-2-implementación-de-agregación-de-enlaces)
    - [Tarea 2.1: Configuración del Modo Alta Disponibilidad](#tarea-21-configuración-del-modo-alta-disponibilidad)
      - [Verificación de interfaces disponibles](#verificación-de-interfaces-disponibles)
      - [Carga del módulo bonding](#carga-del-módulo-bonding)
      - [Creación de la interfaz bond0](#creación-de-la-interfaz-bond0)
      - [Adición de interfaces esclavas](#adición-de-interfaces-esclavas)
      - [Configuración de red](#configuración-de-red)
      - [Validación de la configuración](#validación-de-la-configuración)
    - [Tarea 2.2: Configuración del Modo Balanceo de Carga](#tarea-22-configuración-del-modo-balanceo-de-carga)
      - [Modificación del modo de operación](#modificación-del-modo-de-operación)
      - [Verificación del nuevo modo](#verificación-del-nuevo-modo)
  - [Fase 3: Pruebas y Validación](#fase-3-pruebas-y-validación)
    - [Tarea 3.1: Validación del Modo Alta Disponibilidad](#tarea-31-validación-del-modo-alta-disponibilidad)
      - [Configuración para pruebas de alta disponibilidad](#configuración-para-pruebas-de-alta-disponibilidad)
      - [Prueba de conmutación por error](#prueba-de-conmutación-por-error)
    - [Tarea 3.2: Validación del Modo Balanceo de Carga](#tarea-32-validación-del-modo-balanceo-de-carga)
      - [Configuración para pruebas de rendimiento](#configuración-para-pruebas-de-rendimiento)
      - [Instalación de herramientas de prueba](#instalación-de-herramientas-de-prueba)
      - [Configuración del servidor de pruebas](#configuración-del-servidor-de-pruebas)
      - [Prueba de rendimiento en modo balance-rr](#prueba-de-rendimiento-en-modo-balance-rr)
    - [Tarea 3.3: Análisis Comparativo de Rendimiento](#tarea-33-análisis-comparativo-de-rendimiento)
      - [Prueba de rendimiento en modo active-backup](#prueba-de-rendimiento-en-modo-active-backup)
      - [Análisis de los resultados](#análisis-de-los-resultados)
  - [Solución de Problemas](#solución-de-problemas)
    - [Problema 1: Pérdida de conectividad en modo 802.3ad](#problema-1-pérdida-de-conectividad-en-modo-8023ad)
    - [Problema 2: Interfaces no agregándose al bond](#problema-2-interfaces-no-agregándose-al-bond)
  - [Conclusiones](#conclusiones)
    - [Modo Active-Backup](#modo-active-backup)
    - [Modo Balance-RR](#modo-balance-rr)
    - [Consideraciones para Implementación](#consideraciones-para-implementación)
  - [Bibliografía](#bibliografía)

## Introducción

La agregación de enlaces (_Network Link Bonding_) constituye una técnica fundamental en la administración de redes que permite combinar múltiples interfaces físicas de red en una única interfaz lógica. Esta tecnología proporciona beneficios críticos para la infraestructura de red, incluyendo el incremento del ancho de banda disponible y la mejora de la tolerancia a fallos del sistema.

En el contexto de sistemas Linux, el módulo del kernel `bonding` implementa esta funcionalidad siguiendo diversos algoritmos de agregación, cada uno optimizado para escenarios específicos de uso. La presente práctica se enfoca en la implementación y validación de dos modos principales: **active-backup** para alta disponibilidad y **balance-rr** para distribución de carga.

El entorno de virtualización KVM proporciona un marco adecuado para la experimentación con estas tecnologías, permitiendo la simulación de múltiples interfaces de red y la validación de comportamientos de conmutación por error sin requerir hardware físico especializado.

## Objetivos

Los objetivos específicos de esta práctica son:

1. **Implementar** una configuración de agregación de enlaces en una máquina virtual Fedora utilizando NetworkManager y el módulo bonding del kernel.
2. **Configurar** dos perfiles de agregación distintos:
   - Modo _active-backup_ (modo 1) para proporcionar alta disponibilidad
   - Modo _balance-rr_ (modo 0) para optimización de rendimiento
3. **Validar** el funcionamiento correcto de cada configuración mediante pruebas de conmutación por error y medición de rendimiento.
4. **Analizar** las ventajas y limitaciones de cada modo en entornos virtualizados.

## Fase 1: Preparación del Entorno Virtual

### Tarea 1.1: Creación de la Máquina Virtual

La creación de la máquina virtual se realiza utilizando la herramienta `virt-install`, configurando múltiples interfaces de red para simular el entorno de agregación de enlaces.

```bash
virt-install \
  --name Bond \
  --vcpus 1 \
  --memory 2048 \
  --disk size=10,format=qcow2,bus=virtio \
  --os-variant fedora40 \
  --cdrom /ISO/Fedora-Server-netinst-x86_64-41-1.4.iso \
  --network network=default,model=virtio \
  --network network=default,model=virtio \
  --network network=default,model=virtio \
  --console pty,target_type=serial
```

**Explicación del comando**:

- `virt-install`: Herramienta para crear máquinas virtuales en sistemas basados en libvirt
- `--name Bond`: Asigna el nombre "Bond" a la máquina virtual
- `--vcpus 1 --memory 2048`: Configura recursos mínimos suficientes para las pruebas
- `--network network=default,model=virtio`: Crea tres interfaces de red virtuales utilizando el modelo virtio para mayor rendimiento
- `--console pty,target_type=serial`: Habilita acceso de consola serie para administración remota

La configuración resultante proporciona tres interfaces de red con las siguientes direcciones MAC:

```bash
virsh domifaddr Bond
```

```
 Nombre     dirección MAC       Protocol     Address
-------------------------------------------------------------------------------
 vnet6      52:54:00:3f:99:f0    ipv4         192.168.122.76/24
 vnet7      52:54:00:ee:18:de    ipv4         192.168.122.66/24
 vnet8      52:54:00:33:75:d2    ipv4         192.168.122.227/24
```

### Tarea 1.2: Configuración Inicial del Sistema

La configuración inicial del sistema incluye la actualización de paquetes, instalación de servicios necesarios y configuración de acceso remoto.

#### Actualización del sistema

```bash
dnf upgrade --refresh
```

**Explicación del comando**:

- `dnf upgrade --refresh`: Actualiza todos los paquetes del sistema y refresca los metadatos de los repositorios

#### Instalación y configuración del agente QEMU

```bash
dnf install -y qemu-guest-agent
systemctl enable --now qemu-guest-agent
```

**Explicación del comando**:

- `qemu-guest-agent`: Proporciona comunicación bidireccional entre el hipervisor y la máquina virtual
- `systemctl enable --now`: Habilita e inicia el servicio simultáneamente

#### Configuración del hostname

```bash
hostnamectl set-hostname bond.vpd.com
```

**Explicación del comando**:

- `hostnamectl set-hostname`: Establece el nombre del sistema de forma persistente

#### Configuración de acceso SSH

```bash
ssh-copy-id root@192.168.122.76
```

Esta configuración permite el acceso remoto mediante claves públicas, eliminando la necesidad de autenticación por contraseña para las tareas de administración posteriores.

## Fase 2: Implementación de Agregación de Enlaces

### Tarea 2.1: Configuración del Modo Alta Disponibilidad

El modo _active-backup_ proporciona redundancia mediante un esquema de conmutación automática por error, donde una interfaz permanece activa mientras las demás actúan como respaldo.

#### Verificación de interfaces disponibles

```bash
nmcli device status
```

```
DEVICE  TYPE      STATE                   CONNECTION
enp1s0  ethernet  conectado               enp1s0
enp2s0  ethernet  conectado               enp2s0
enp3s0  ethernet  conectado               enp3s0
lo      loopback  connected (externally)  lo
```

#### Carga del módulo bonding

```bash
modprobe bonding
echo "bonding" | tee /etc/modules-load.d/bonding.conf
```

**Explicación del comando**:

- `modprobe bonding`: Carga el módulo del kernel necesario para la agregación de enlaces
- El archivo en `/etc/modules-load.d/` asegura la carga automática del módulo en futuros reinicios

> **Nota**: En Fedora 41, NetworkManager carga automáticamente el módulo bonding cuando es necesario, haciendo opcional este paso.

#### Creación de la interfaz bond0

```bash
nmcli connection add type bond con-name bond0 ifname bond0 bond.options "mode=active-backup,miimon=100"
```

**Explicación del comando**:

- `type bond`: Especifica la creación de una interfaz de agregación
- `mode=active-backup`: Configura el modo de alta disponibilidad
- `miimon=100`: Establece el intervalo de monitoreo de enlaces en 100 milisegundos

#### Adición de interfaces esclavas

```bash
for IF in enp1s0 enp2s0 enp3s0; do
    nmcli connection add type ethernet \
        port-type bond controller bond0 \
        con-name ${IF}-port ifname $IF
done
```

**Explicación del comando**:

- `port-type bond controller bond0`: Configura las interfaces como puertos esclavos del bond
- El bucle automatiza la configuración de las tres interfaces disponibles

#### Configuración de red

```bash
nmcli connection modify bond0 ipv4.addresses 192.168.122.57/24 ipv4.gateway 192.168.122.1 ipv4.dns "8.8.8.8 1.1.1.1" ipv4.method manual
nmcli con up bond0
```

**Explicación del comando**:

- Se configura una dirección IP estática para facilitar las pruebas posteriores
- `ipv4.method manual`: Especifica configuración manual en lugar de DHCP

#### Validación de la configuración

```bash
cat /proc/net/bonding/bond0
```

La salida muestra el estado actual del bond:

```
Ethernet Channel Bonding Driver: v6.14.6-200.fc41.x86_64

Bonding Mode: fault-tolerance (active-backup)
Primary Slave: None
Currently Active Slave: enp1s0
MII Status: up
MII Polling Interval (ms): 100

Slave Interface: enp1s0
MII Status: up
Speed: Unknown
Duplex: Unknown
Link Failure Count: 0
Permanent HW addr: 52:54:00:3f:99:f0

Slave Interface: enp2s0
MII Status: up
Speed: Unknown
Duplex: Unknown
Link Failure Count: 0
Permanent HW addr: 52:54:00:ee:18:de

Slave Interface: enp3s0
MII Status: up
Speed: Unknown
Duplex: Unknown
Link Failure Count: 0
Permanent HW addr: 52:54:00:33:75:d2
```

La configuración confirma que `enp1s0` está actualmente activa como interfaz principal.

### Tarea 2.2: Configuración del Modo Balanceo de Carga

El modo _balance-rr_ distribuye los paquetes secuencialmente entre todas las interfaces disponibles, proporcionando potencial mejora de rendimiento mediante la utilización simultánea de múltiples enlaces.

#### Modificación del modo de operación

```bash
nmcli connection modify bond0 bond.options "mode=balance-rr,miimon=100"
nmcli connection down bond0 && nmcli connection up bond0
```

**Explicación del comando**:

- `mode=balance-rr`: Establece el modo de balanceo Round-Robin
- La desactivación y reactivación de la conexión aplica los cambios de configuración

#### Verificación del nuevo modo

```bash
cat /proc/net/bonding/bond0
```

```
Bonding Mode: load balancing (round-robin)
MII Status: up
MII Polling Interval (ms): 100

Slave Interface: enp1s0
MII Status: up
Slave queue ID: 0

Slave Interface: enp2s0
MII Status: up
Slave queue ID: 0

Slave Interface: enp3s0
MII Status: up
Slave queue ID: 0
```

La salida confirma que todas las interfaces están activas y disponibles para la distribución de tráfico.

## Fase 3: Pruebas y Validación

### Tarea 3.1: Validación del Modo Alta Disponibilidad

#### Configuración para pruebas de alta disponibilidad

```bash
nmcli connection modify bond0 bond.options "mode=active-backup,miimon=100"
nmcli connection down bond0 && nmcli connection up bond0
```

#### Prueba de conmutación por error

La validación del modo active-backup requiere simular el fallo de la interfaz activa y verificar la conmutación automática:

```bash
# Verificación del estado inicial
cat /proc/net/bonding/bond0 | grep "Currently Active Slave"
```

```
Currently Active Slave: enp1s0
```

```bash
# Simulación de fallo de la interfaz activa
ip link set enp1s0 down
```

```bash
# Verificación de continuidad del servicio
ping -c 4 8.8.8.8
```

```
PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=114 time=29.9 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=114 time=30.4 ms
64 bytes from 8.8.8.8: icmp_seq=3 ttl=114 time=28.8 ms
64 bytes from 8.8.8.8: icmp_seq=4 ttl=114 time=31.2 ms
```

```bash
# Verificación de la nueva interfaz activa
cat /proc/net/bonding/bond0 | grep "Currently Active Slave"
```

```
Currently Active Slave: enp2s0
```

**Análisis de resultados**: La prueba demuestra que la conmutación automática funciona correctamente. Cuando la interfaz `enp1s0` se deshabilita, el sistema selecciona automáticamente `enp2s0` como nueva interfaz activa, manteniendo la conectividad sin interrupciones perceptibles.

### Tarea 3.2: Validación del Modo Balanceo de Carga

#### Configuración para pruebas de rendimiento

```bash
nmcli connection modify bond0 bond.options "mode=balance-rr,miimon=100"
nmcli connection down bond0 && nmcli connection up bond0
```

#### Instalación de herramientas de prueba

```bash
dnf install -y iperf3
```

#### Configuración del servidor de pruebas

En el sistema anfitrión:

```bash
# Configuración del firewall
firewall-cmd --zone=libvirt --permanent --add-port=5201/tcp
firewall-cmd --zone=libvirt --permanent --add-port=5201/udp
firewall-cmd --reload

# Inicio del servidor iperf3
iperf3 -s
```

#### Prueba de rendimiento en modo balance-rr

```bash
iperf3 -c 192.168.122.1 -P 3 -t 30
```

**Explicación del comando**:

- `-c 192.168.122.1`: Especifica el servidor destino
- `-P 3`: Utiliza tres flujos paralelos para aprovechar la distribución de carga
- `-t 30`: Duración de la prueba en segundos

**Resultados obtenidos**:

```
[SUM]   0.00-30.00  sec  72.1 GBytes  20.6 Gbits/sec  1777             sender
[SUM]   0.00-30.00  sec  72.1 GBytes  20.6 Gbits/sec                  receiver
```

### Tarea 3.3: Análisis Comparativo de Rendimiento

#### Prueba de rendimiento en modo active-backup

```bash
nmcli connection modify bond0 bond.options "mode=active-backup,miimon=100"
nmcli connection down bond0 && nmcli connection up bond0

iperf3 -c 192.168.122.1 -t 30
```

**Resultados obtenidos**:

```
[  5]   0.00-30.00  sec  82.6 GBytes  23.7 Gbits/sec    0             sender
[  5]   0.00-30.00  sec  82.6 GBytes  23.7 Gbits/sec                  receiver
```

#### Análisis de los resultados

| Modo          | Rendimiento Promedio | Número de Flujos   | Observaciones                           |
| ------------- | -------------------- | ------------------ | --------------------------------------- |
| balance-rr    | 20.6 Gbits/sec       | 3 flujos paralelos | Distribución entre múltiples interfaces |
| active-backup | 23.7 Gbits/sec       | 1 flujo único      | Una sola interfaz activa                |

**Interpretación de los resultados**:

En el entorno virtualizado evaluado, el modo _active-backup_ muestra un rendimiento superior en términos de throughput bruto. Este comportamiento se debe a varios factores específicos del entorno de virtualización:

1. **Optimización de flujo único**: El hipervisor KVM y las interfaces virtio están optimizadas para manejar flujos únicos de alto rendimiento.

2. **Sobrecarga del modo balance-rr**: La distribución round-robin introduce overhead adicional en el procesamiento de paquetes, especialmente en entornos virtualizados.

3. **Limitaciones del bridge virtual**: Todas las interfaces convergen en el mismo bridge NAT, limitando los beneficios de la distribución de carga.

> **Nota**: En entornos físicos con múltiples destinos y switches conmutados, el modo balance-rr típicamente proporciona mejores resultados de rendimiento agregado.

## Solución de Problemas

### Problema 1: Pérdida de conectividad en modo 802.3ad

**Síntomas**:

- Pérdida total de conectividad SSH tras cambiar a modo 802.3ad
- Interfaces marcadas como "down" en el estado del bond

**Solución**:

1. Acceder por consola local a la máquina virtual
2. Cambiar de vuelta a modo active-backup:

```bash
nmcli connection modify bond0 bond.options "mode=active-backup,miimon=100"
nmcli connection down bond0 && nmcli connection up bond0
```

3. Verificar que se restaura la conectividad

**Explicación**: El modo 802.3ad requiere soporte LACP en el switch, que no está disponible en el bridge NAT por defecto de libvirt.

### Problema 2: Interfaces no agregándose al bond

**Síntomas**:

- El bond se crea pero no lista interfaces esclavas
- Comando `nmcli con up bond0` falla

**Solución**:

1. Verificar que las conexiones de puerto están correctamente configuradas:

```bash
nmcli connection show
```

2. Activar manualmente las conexiones de puerto:

```bash
for IF in enp1s0 enp2s0 enp3s0; do
    nmcli con up ${IF}-port
done
```

## Conclusiones

La implementación de agregación de enlaces mediante bonding en entornos virtualizados KVM demuestra ser una técnica efectiva para proporcionar tanto alta disponibilidad como distribución de carga, aunque con consideraciones específicas para cada modo de operación.

### Modo Active-Backup

El modo _active-backup_ cumple eficazmente su objetivo principal de proporcionar alta disponibilidad. Las pruebas de conmutación por error demuestran que:

- La transición entre interfaces es completamente transparente para las aplicaciones
- No se observa pérdida significativa de paquetes durante la conmutación
- El tiempo de recuperación es prácticamente inmediato (< 100ms)

Este modo es la opción recomendada para entornos donde la continuidad del servicio es prioritaria sobre el rendimiento máximo.

### Modo Balance-RR

El modo _balance-rr_ proporciona distribución de carga entre múltiples interfaces, aunque en entornos virtualizados los beneficios de rendimiento pueden ser limitados por:

- Optimizaciones específicas del hipervisor para flujos únicos
- Overhead adicional de la distribución round-robin
- Limitaciones arquitecturales del networking virtual

Sin embargo, este modo mantiene ventajas importantes en escenarios con múltiples flujos concurrentes y diferentes destinos.

### Consideraciones para Implementación

1. **Elección del modo**: La selección entre modos debe basarse en los requisitos específicos del entorno (disponibilidad vs. rendimiento).

2. **Limitaciones del entorno virtual**: Los beneficios de rendimiento de la agregación pueden ser menores en entornos virtualizados comparados con implementaciones físicas.

3. **Monitoreo continuo**: Es esencial implementar monitoreo del estado de los enlaces para detectar y responder a fallos de forma proactiva.

La tecnología de agregación de enlaces representa una herramienta fundamental para el diseño de infraestructuras de red resilientes y de alto rendimiento, proporcionando flexibilidad para adaptarse a diferentes requisitos operacionales.

## Bibliografía

1. Red Hat, Inc. (2024). _Red Hat Enterprise Linux 8 - Configuring and Managing Networking - Configuring network bonding_. [Documentación oficial](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/configuring-network-bonding_configuring-and-managing-networking)

2. Kernel.org. (2024). _Linux Ethernet Bonding Driver HOWTO_. [Documentación del kernel Linux](https://www.kernel.org/doc/Documentation/networking/bonding.txt)

3. Fedora Project. (2024). _Fedora 41 System Administrator's Guide - Network Bonding_. [Documentación de Fedora](https://docs.fedoraproject.org/en-US/fedora/latest/system-administrators-guide/networking/Network_Bonding/)

4. NetworkManager Project. (2024). _NetworkManager Reference Manual_. [Manual de referencia](https://networkmanager.dev/docs/api/latest/)
